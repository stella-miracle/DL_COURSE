{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpfy-NIfcOjR"
      },
      "outputs": [],
      "source": [
        "# 1. Setting up Keras Tuner\n",
        "import keras_tuner as kt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "(x_train,y_train),(x_test,y_test) = mmist.load_data()\n",
        "x_val, y_val  = x_val/255.0 , y_val/255.0\n",
        "\n",
        "print(f'Shape of x_train: {x_train.shape}')\n",
        "print(f'Shape of x_test: {x_val.shape}')\n",
        "\n",
        "# 2. build model\n",
        "\n",
        "def build_model(hp):\n",
        "    model = Sequential([\n",
        "    model.add(Flatten(input_shape=(28,28)),\n",
        "              Dense(units = hp.Int(\"unit\",min_value = 32, max_value = 512, step = 32),\n",
        "                    activation = 'relu'),\n",
        "              Dense(10, activation = \"softmax\"))\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        qtimizer = Adam(learning_rate =hp.Float('learning_rate,'min_val`=1e-4, max_value = 1e-2, sampling = \"log\")),\n",
        "                  loss = \"sparse_categorical_crossentropy\",\n",
        "        metrics = [\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "#3.Configuring the hyperparameter search objective\n",
        "\n",
        "tuner = kt.RandomSearch(\n",
        "    build_model,\n",
        "    objective = \"val_accuracy\",#val_accuracy 를 최적하는것이 objective\n",
        "    max_trials = 10, # 최대 시도 횟수\n",
        "    executions_per_trial = 2, # 2번 실행해서 평균결과를 사용\n",
        "    directory = \"my_dir\",\n",
        "    project_name = \"mnist_to_keras tuner\"\n",
        ")\n",
        "\n",
        "tuner.search_space_summary()\n",
        "\n",
        "\n",
        "# 4. Running the hyperparameter search\n",
        "tuner.search(x_train, y_train, epochs =5, validation_data = (x_val, y_val))\n",
        "tuner.results_summary()\n",
        "\n",
        "# 5. Analyzing and using the best hyperparameter\n",
        "best_hy = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
        "# (num_trials = 1) 가장 성능이 좋았던 \"1\"개의 파라미터 조합을 가져옴\n",
        "# [0] 그중에서 첫번쨰 값을 불러오기\n",
        "print(f\"\"\"\n",
        "\n",
        "The optimal number of units in the first dense layer is {best_hps.get('units')}.\n",
        "\n",
        "The optimal learning rate for the optimizer is {best_hps.get('learning_rate')}.\n",
        "\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "# Rebuild and train the model with best hyperparameters\n",
        "model = tuner.hypermodel.build(best_hy)\n",
        "history = model.fit(x_train, y_train, epochs = 10, validation_split= 0.2)\n",
        "\n",
        "#evaluate the model on the validation set\n",
        "val_loss, val_acc = model.evaluate(x_val, y_val)\n",
        "print(f\"Validation accuracy: {val_acc}\")\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}